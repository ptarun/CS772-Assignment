{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset, get_dataset_config_names\nsquad_data_train, squad_data_test = load_dataset('squad_v2', split=['train','validation'])\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-01T16:08:56.38076Z","iopub.execute_input":"2022-04-01T16:08:56.381312Z","iopub.status.idle":"2022-04-01T16:09:17.807716Z","shell.execute_reply.started":"2022-04-01T16:08:56.381273Z","shell.execute_reply":"2022-04-01T16:09:17.807009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"squad_data_train","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:12:39.877874Z","iopub.execute_input":"2022-04-01T16:12:39.878581Z","iopub.status.idle":"2022-04-01T16:12:39.884626Z","shell.execute_reply.started":"2022-04-01T16:12:39.878543Z","shell.execute_reply":"2022-04-01T16:12:39.883782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom operator import itemgetter\ndf_train = pd.DataFrame(columns = ['context','question','answer'])\ndf_train['context'], df_train['question'], df_train['answer'] = squad_data_train['context'],  squad_data_train['question'],  list(map(itemgetter('text'), squad_data_train['answers'] ))\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:12:42.587137Z","iopub.execute_input":"2022-04-01T16:12:42.587395Z","iopub.status.idle":"2022-04-01T16:12:46.43243Z","shell.execute_reply.started":"2022-04-01T16:12:42.587367Z","shell.execute_reply":"2022-04-01T16:12:46.431748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test= pd.DataFrame(columns = ['context','question','answer'])\ndf_test['context'], df_test['question'], df_test['answer'] = squad_data_test['context'],  squad_data_test['question'],  list(map(itemgetter('text'), squad_data_test['answers'] ))\n\ndf_train.append(df_test, ignore_index = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:12:49.463457Z","iopub.execute_input":"2022-04-01T16:12:49.464296Z","iopub.status.idle":"2022-04-01T16:12:49.707058Z","shell.execute_reply.started":"2022-04-01T16:12:49.464245Z","shell.execute_reply":"2022-04-01T16:12:49.706372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing rows with no answers\ndf_train = df_train.loc[df_train['answer'].apply(lambda x: len(x) == 1)]\n# making list of answer to a string\ndf_train['answer'] = df_train['answer'].apply(lambda x: x[0])\ndf_train.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:12:52.738886Z","iopub.execute_input":"2022-04-01T16:12:52.739627Z","iopub.status.idle":"2022-04-01T16:12:52.851611Z","shell.execute_reply.started":"2022-04-01T16:12:52.739587Z","shell.execute_reply":"2022-04-01T16:12:52.850916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndf_train['answer'] = df_train['answer'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\ndf_train['context'] = df_train['context'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\ndf_train['question'] = df_train['question'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:12:58.242754Z","iopub.execute_input":"2022-04-01T16:12:58.243027Z","iopub.status.idle":"2022-04-01T16:13:00.862628Z","shell.execute_reply.started":"2022-04-01T16:12:58.242997Z","shell.execute_reply":"2022-04-01T16:13:00.861888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing rows with long answer\ndf_train  = df_train.loc[df_train['answer'].apply(lambda x: len(x.split()) <= 6)]\ndf_train.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:13:07.896023Z","iopub.execute_input":"2022-04-01T16:13:07.896751Z","iopub.status.idle":"2022-04-01T16:13:07.980004Z","shell.execute_reply.started":"2022-04-01T16:13:07.896704Z","shell.execute_reply":"2022-04-01T16:13:07.979291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make all lower case\ndf_train['context'], df_train['question'], df_train['answer'] = df_train['context'].str.lower(), df_train['question'].str.lower(), df_train['answer'].str.lower()\ndf_train = df_train.reset_index(drop=True)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:13:12.229831Z","iopub.execute_input":"2022-04-01T16:13:12.230705Z","iopub.status.idle":"2022-04-01T16:13:12.475487Z","shell.execute_reply.started":"2022-04-01T16:13:12.230661Z","shell.execute_reply":"2022-04-01T16:13:12.474795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add <bos> and <eos> symbol for answer\ndf_train['answer'] = df_train['answer'].apply(lambda x: 'bos ' + x + ' eos' )\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:13:20.884839Z","iopub.execute_input":"2022-04-01T16:13:20.885594Z","iopub.status.idle":"2022-04-01T16:13:20.933436Z","shell.execute_reply.started":"2022-04-01T16:13:20.885559Z","shell.execute_reply":"2022-04-01T16:13:20.932777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk import word_tokenize\ndf_train['answer'] = df_train.apply(lambda row: word_tokenize(row['answer']), axis=1)\ndf_train['question'] = df_train.apply(lambda row: word_tokenize(row['question']), axis=1)\ndf_train['context'] = df_train.apply(lambda row: word_tokenize(row['context']), axis=1)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-04-01T16:13:28.082621Z","iopub.execute_input":"2022-04-01T16:13:28.083066Z","iopub.status.idle":"2022-04-01T16:15:11.559599Z","shell.execute_reply.started":"2022-04-01T16:13:28.083023Z","shell.execute_reply":"2022-04-01T16:15:11.558807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n#df_train.to_pickle(\"./data_tokenized2.pkl\")  \ndf_train = pd.read_pickle(\"../input/squadtokenised/data_tokenized2 (1).pkl\")  \ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:09:04.892914Z","iopub.execute_input":"2022-04-02T07:09:04.893258Z","iopub.status.idle":"2022-04-02T07:09:08.019484Z","shell.execute_reply.started":"2022-04-02T07:09:04.893172Z","shell.execute_reply":"2022-04-02T07:09:08.018684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['context'].apply(len).min()","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:09:12.463657Z","iopub.execute_input":"2022-04-02T07:09:12.463916Z","iopub.status.idle":"2022-04-02T07:09:12.511998Z","shell.execute_reply.started":"2022-04-02T07:09:12.463887Z","shell.execute_reply":"2022-04-02T07:09:12.511295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change the values later\nmax_c_len = 130\nmax_q_len = 20\nmax_a_len = 6","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:09:14.802785Z","iopub.execute_input":"2022-04-02T07:09:14.803061Z","iopub.status.idle":"2022-04-02T07:09:14.80724Z","shell.execute_reply.started":"2022-04-02T07:09:14.80302Z","shell.execute_reply":"2022-04-02T07:09:14.806218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating numpy arrays of text\nimport numpy as np\ntrain_c = np.array(df_train['context'])\ntrain_q = np.array(df_train['question'])\ntrain_a = np.array(df_train['answer'])\ntxt = np.concatenate((train_a, train_q, train_c), axis=None)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:09:18.192263Z","iopub.execute_input":"2022-04-02T07:09:18.192746Z","iopub.status.idle":"2022-04-02T07:09:18.205787Z","shell.execute_reply.started":"2022-04-02T07:09:18.192705Z","shell.execute_reply":"2022-04-02T07:09:18.204821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train tokenizer\nfrom tensorflow.keras.preprocessing.text import Tokenizer \nx_tokenizer = Tokenizer() \nx_tokenizer.fit_on_texts(txt)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:09:23.329529Z","iopub.execute_input":"2022-04-02T07:09:23.329794Z","iopub.status.idle":"2022-04-02T07:09:36.46463Z","shell.execute_reply.started":"2022-04-02T07:09:23.329765Z","shell.execute_reply":"2022-04-02T07:09:36.463827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_size = len(x_tokenizer.word_index) + 1\nvoc_size","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:09:44.153104Z","iopub.execute_input":"2022-04-02T07:09:44.153359Z","iopub.status.idle":"2022-04-02T07:09:44.158905Z","shell.execute_reply.started":"2022-04-02T07:09:44.15333Z","shell.execute_reply":"2022-04-02T07:09:44.158064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!wget http://nlp.stanford.edu/data/glove.6B.zip","metadata":{"execution":{"iopub.status.busy":"2022-04-01T15:14:22.785855Z","iopub.execute_input":"2022-04-01T15:14:22.786175Z","iopub.status.idle":"2022-04-01T15:14:22.798218Z","shell.execute_reply.started":"2022-04-01T15:14:22.786149Z","shell.execute_reply":"2022-04-01T15:14:22.797609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!unzip glove*.zip","metadata":{"execution":{"iopub.status.busy":"2022-04-01T15:14:22.800047Z","iopub.execute_input":"2022-04-01T15:14:22.800645Z","iopub.status.idle":"2022-04-01T15:14:22.810286Z","shell.execute_reply.started":"2022-04-01T15:14:22.800603Z","shell.execute_reply":"2022-04-01T15:14:22.809519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################testing\n\nf = open('../input/glove-embeddings/glove.6B.300d.txt', 'r')\nlines = f.readlines()\n\nfrom tqdm import tqdm\nimport numpy as np\nwords_list = []\nglove_emb = {}\nfor i, line in enumerate(lines):\n    line = line.strip('\\n')\n    tokens = line.split()\n    temp = list(map(float, tokens[1:]))\n    word = tokens[0].lower()\n    words_list.append(word)\n    glove_emb[word] = np.array(temp)\n    #print(len(temp))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:09:47.693446Z","iopub.execute_input":"2022-04-02T07:09:47.694013Z","iopub.status.idle":"2022-04-02T07:10:41.366824Z","shell.execute_reply.started":"2022-04-02T07:09:47.693973Z","shell.execute_reply":"2022-04-02T07:10:41.366011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tokens = len(x_tokenizer.word_index) + 1\nembedding_dim = 300\nhits = 0\nmisses = 0\nm = []\n# Prepare embedding matrix\nembedding_matrix = np.zeros((num_tokens, embedding_dim))\nfor word, i in x_tokenizer.word_index.items():\n    try:\n        embedding_vector = glove_emb[word]\n    \n        # Words not found in embedding index will be all-zeros.\n        # This includes the representation for \"padding\" and \"OOV\"\n        embedding_matrix[i] = embedding_vector\n        hits += 1\n    except:\n        misses += 1\n        m.append(word)\n        #print(word)\nprint(\"Converted %d words (%d misses)\" % (hits, misses))\n\n################################testing ended\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:10:58.188804Z","iopub.execute_input":"2022-04-02T07:10:58.189113Z","iopub.status.idle":"2022-04-02T07:10:58.596886Z","shell.execute_reply.started":"2022-04-02T07:10:58.18908Z","shell.execute_reply":"2022-04-02T07:10:58.596175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" x_tokenizer.texts_to_sequences(['bos','eos'])","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:11:01.142158Z","iopub.execute_input":"2022-04-02T07:11:01.142621Z","iopub.status.idle":"2022-04-02T07:11:01.153254Z","shell.execute_reply.started":"2022-04-02T07:11:01.142575Z","shell.execute_reply":"2022-04-02T07:11:01.152337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#embedding_matrix[11]","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:11:03.684047Z","iopub.execute_input":"2022-04-02T07:11:03.684508Z","iopub.status.idle":"2022-04-02T07:11:03.690051Z","shell.execute_reply.started":"2022-04-02T07:11:03.684471Z","shell.execute_reply":"2022-04-02T07:11:03.689102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\ntrain_emb_c = x_tokenizer.texts_to_sequences(train_c) \ntrain_emb_q = x_tokenizer.texts_to_sequences(train_q) \ntrain_emb_a = x_tokenizer.texts_to_sequences(train_a) ","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:11:05.30589Z","iopub.execute_input":"2022-04-02T07:11:05.306467Z","iopub.status.idle":"2022-04-02T07:11:10.534739Z","shell.execute_reply.started":"2022-04-02T07:11:05.306426Z","shell.execute_reply":"2022-04-02T07:11:10.53397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making all instances same length\ntrain_emb_c = pad_sequences(train_emb_c,  maxlen=max_c_len, padding='post')\ntrain_emb_q = pad_sequences(train_emb_q,  maxlen=max_q_len, padding='post')\ntrain_emb_a = pad_sequences(train_emb_a,  maxlen=max_a_len, padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:11:53.994921Z","iopub.execute_input":"2022-04-02T07:11:53.995221Z","iopub.status.idle":"2022-04-02T07:11:55.986148Z","shell.execute_reply.started":"2022-04-02T07:11:53.995181Z","shell.execute_reply":"2022-04-02T07:11:55.985376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_c_len\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:11:58.247847Z","iopub.execute_input":"2022-04-02T07:11:58.248367Z","iopub.status.idle":"2022-04-02T07:11:58.253482Z","shell.execute_reply.started":"2022-04-02T07:11:58.248313Z","shell.execute_reply":"2022-04-02T07:11:58.252713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model 1 \nfrom keras import backend as K \nK.clear_session() \nlatent_dim = 300 \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport string\nfrom string import digits\nimport re\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed,Attention\nfrom tensorflow.keras.models import Model,load_model, model_from_json\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.preprocessing.text import one_hot, Tokenizer\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport pickle as pkl\nimport numpy as np\n\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention\nK.clear_session() \nlatent_dim = 300\n# Encoder \nencoder_inputs = Input(shape=(max_q_len,)) \nenc_emb = Embedding(voc_size, latent_dim,weights=[embedding_matrix],trainable=True)(encoder_inputs)\n#LSTM 1 \nencoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \nencoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n#LSTM 2 \nencoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \nencoder_output, state_h, state_c = encoder_lstm2(encoder_output1)\n'''\n\n#LSTM 3 \nencoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \nencoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n'''\n\n#context lstm\n \ncontext_inputs = Input(shape=(max_c_len,)) \ncontxt_emb = Embedding(voc_size, latent_dim, weights=[embedding_matrix],trainable=True)(context_inputs) \n#LSTM 1 \ncontext_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \ncontext_output1, context_state_h1, context_state_c1 = context_lstm1(contxt_emb) \n\n\n#LSTM 2 \ncontext_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \ncontext_output, context_state_h, context_state_c = context_lstm2(context_output1)\n\n'''\n#LSTM 3 \ncontext_lstm3 = LSTM(latent_dim,return_sequences=True,return_state=True) \ncontext_output, context_state_h, context_state_c = context_lstm3(context_output2)\n'''\n\n\n# Set up the decoder. \ndecoder_inputs = Input(shape=(None,)) \ndec_emb_layer = Embedding(voc_size, latent_dim,weights=[embedding_matrix],trainable=True) \ndec_emb = dec_emb_layer(decoder_inputs)\n#LSTM using encoder_states as initial state\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \ndecoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n\n#Attention Layer\nattn_out = Attention()([decoder_outputs , context_output]) \n#attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n\n\n# Concat attention output and decoder LSTM output \ndecoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n#Dense layer\ndecoder_dense = TimeDistributed(Dense(voc_size, activation='softmax')) \ndecoder_outputs = decoder_dense(decoder_concat_input)\n# Define the model\nmodel = Model([encoder_inputs, context_inputs, decoder_inputs], decoder_outputs) \nplot_model(model, to_file='train_model.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:12:01.963752Z","iopub.execute_input":"2022-04-02T07:12:01.964005Z","iopub.status.idle":"2022-04-02T07:12:08.256065Z","shell.execute_reply.started":"2022-04-02T07:12:01.963977Z","shell.execute_reply":"2022-04-02T07:12:08.255259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop',\n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:12:12.187978Z","iopub.execute_input":"2022-04-02T07:12:12.188268Z","iopub.status.idle":"2022-04-02T07:12:12.207222Z","shell.execute_reply.started":"2022-04-02T07:12:12.188236Z","shell.execute_reply":"2022-04-02T07:12:12.206455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test, c_train, c_test = train_test_split( train_emb_q, train_emb_a, train_emb_c, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:12:14.212199Z","iopub.execute_input":"2022-04-02T07:12:14.212915Z","iopub.status.idle":"2022-04-02T07:12:14.25228Z","shell.execute_reply.started":"2022-04-02T07:12:14.212876Z","shell.execute_reply":"2022-04-02T07:12:14.251531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([X_train, c_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1])[:,1:], \n                    epochs=40, \n                    callbacks=[es],\n                    batch_size=512,\n                   )\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T07:21:17.323202Z","iopub.execute_input":"2022-04-02T07:21:17.32347Z","iopub.status.idle":"2022-04-02T08:09:50.915528Z","shell.execute_reply.started":"2022-04-02T07:21:17.323441Z","shell.execute_reply":"2022-04-02T08:09:50.914285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####model1 inference  # reference == https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n\nlatent_dim=300\n# encoder inference\n\n#print(encoder_outputs.shape)\nencoder_model = Model(inputs=encoder_inputs,outputs=[encoder_output, state_h, state_c])\ncontext_model = Model(inputs=context_inputs,outputs=[context_output, context_state_h, context_state_c])\n# decoder inference\n\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\n\ndecoder_hidden_state_input = Input(shape=(max_q_len, latent_dim))\ndecoder_context_state_input = Input(shape=(max_c_len, latent_dim))\n\n\ndec_emb2= dec_emb_layer(decoder_inputs)\n\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\nattn_out_inf = Attention()([decoder_outputs2 , decoder_context_state_input]) \n\ndecoder_inf_concat = Concatenate(axis=-1, name='concat_layer')([decoder_outputs2, attn_out_inf])\n# A dense softmax layer to generate prob dist. over the target vocabulary\n\ndecoder_outputs2 = decoder_dense(decoder_inf_concat)\n# Final decoder model\ndecoder_model = Model(\n[decoder_inputs] + [decoder_hidden_state_input,decoder_context_state_input,decoder_state_input_h, decoder_state_input_c],\n[decoder_outputs2] + [state_h2, state_c2])","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:13:00.695994Z","iopub.execute_input":"2022-04-02T08:13:00.696246Z","iopub.status.idle":"2022-04-02T08:13:00.928825Z","shell.execute_reply.started":"2022-04-02T08:13:00.696217Z","shell.execute_reply":"2022-04-02T08:13:00.928103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_sequence2(input_seq, conext_seq):\n    # Encode the input as state vectors.\n    e_out, e_h, e_c = encoder_model.predict([input_seq])\n    c_out, c_h, c_c = context_model.predict([conext_seq])\n    #context_output, context_state_h, context_state_c = context_model.predict(context)\n    #context_vector, attention_weights = att(e_h, context_output)\n    \n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Chose the 'bos' word as the first word of the target sequence\n    target_seq[0, 0] = word_to_token['bos']\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out,c_out, e_h, e_c])\n        # prediction\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        if sampled_token_index == 0:\n            break\n        else:\n            sampled_token = token_to_word[sampled_token_index]\n        if(sampled_token!='eos'):\n              decoded_sentence += ' '+sampled_token\n        # stop prediction condition\n        if (sampled_token == 'eos' or len(decoded_sentence.split()) >= (max_a_len)):\n                  stop_condition = True\n        # Update the target sequence \n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n        # Update internal states\n        e_h, e_c = h, c\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:13:05.071352Z","iopub.execute_input":"2022-04-02T08:13:05.072074Z","iopub.status.idle":"2022-04-02T08:13:05.080751Z","shell.execute_reply.started":"2022-04-02T08:13:05.07203Z","shell.execute_reply":"2022-04-02T08:13:05.079851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seq2text(input_seq):\n    newString = ''\n    for i in input_seq:\n        if i != 0:\n            newString = newString + token_to_word[i] + ' '\n\n    return newString","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:13:08.387153Z","iopub.execute_input":"2022-04-02T08:13:08.387684Z","iopub.status.idle":"2022-04-02T08:13:08.392367Z","shell.execute_reply.started":"2022-04-02T08:13:08.38765Z","shell.execute_reply":"2022-04-02T08:13:08.391657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#seq2text(train_emb_q[6]),seq2text(train_emb_q[5])","metadata":{"execution":{"iopub.status.busy":"2022-04-02T00:44:54.871538Z","iopub.execute_input":"2022-04-02T00:44:54.872101Z","iopub.status.idle":"2022-04-02T00:44:54.877522Z","shell.execute_reply.started":"2022-04-02T00:44:54.872045Z","shell.execute_reply":"2022-04-02T00:44:54.874967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_to_token = x_tokenizer.word_index\ntoken_to_word = x_tokenizer.index_word","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:13:10.569686Z","iopub.execute_input":"2022-04-02T08:13:10.569937Z","iopub.status.idle":"2022-04-02T08:13:10.573569Z","shell.execute_reply.started":"2022-04-02T08:13:10.569908Z","shell.execute_reply":"2022-04-02T08:13:10.572801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('predicted')\nprint(decode_sequence2(train_emb_q[102].reshape(1, max_q_len),train_emb_c[102].reshape(1, max_c_len)))\nprint('actual')\nprint(seq2text(train_emb_a[102]),seq2text(train_emb_q[102]))","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:21:22.242135Z","iopub.execute_input":"2022-04-02T08:21:22.242405Z","iopub.status.idle":"2022-04-02T08:21:22.463505Z","shell.execute_reply.started":"2022-04-02T08:21:22.242363Z","shell.execute_reply":"2022-04-02T08:21:22.46279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('predicted')\nprint(decode_sequence2(X_test[102].reshape(1, max_q_len),c_test[102].reshape(1, max_c_len)))\nprint('actual')\nprint(seq2text(y_test[102]),seq2text(X_test[102]))\n ","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:22:55.649226Z","iopub.execute_input":"2022-04-02T08:22:55.649496Z","iopub.status.idle":"2022-04-02T08:22:55.838613Z","shell.execute_reply.started":"2022-04-02T08:22:55.649467Z","shell.execute_reply":"2022-04-02T08:22:55.837901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lcs(X, Y, m, n):\n \n  \n    if m == 0 or n == 0:\n       return 0;\n    elif X[m-1] == Y[n-1]:\n       return 1 + lcs(X, Y, m-1, n-1);\n    else:\n       return max(lcs(X, Y, m, n-1), lcs(X, Y, m-1, n));","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:13:22.152664Z","iopub.execute_input":"2022-04-02T08:13:22.153364Z","iopub.status.idle":"2022-04-02T08:13:22.160408Z","shell.execute_reply.started":"2022-04-02T08:13:22.153323Z","shell.execute_reply":"2022-04-02T08:13:22.157838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_accuracy2(input_seq, conext_seq):\n    # Encode the input as state vectors.\n    e_out, e_h, e_c = encoder_model.predict([input_seq])\n    c_out, c_h, c_c = context_model.predict([conext_seq])\n    #context_output, context_state_h, context_state_c = context_model.predict(context)\n    #context_vector, attention_weights = att(e_h, context_output)\n    \n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Chose the 'bos' word as the first word of the target sequence\n    target_seq[0, 0] = word_to_token['bos']\n    stop_condition = False\n    decoded_sentence = []\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out,c_out, e_h, e_c])\n        # prediction\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        if sampled_token_index == 0:\n            break\n        else:\n            sampled_token = token_to_word[sampled_token_index]\n        if(sampled_token!='eos'):\n              decoded_sentence.append(sampled_token_index)\n        # stop prediction condition\n        if (sampled_token == 'eos' or len(decoded_sentence) >= (max_a_len)):\n                  stop_condition = True\n        # Update the target sequence \n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n        # Update internal states\n        e_h, e_c = h, c\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:13:24.046957Z","iopub.execute_input":"2022-04-02T08:13:24.047226Z","iopub.status.idle":"2022-04-02T08:13:24.058156Z","shell.execute_reply.started":"2022-04-02T08:13:24.047197Z","shell.execute_reply":"2022-04-02T08:13:24.057376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculation of precision recall\n#X_train, X_test, y_train, y_test, c_train, c_test\n#Precision = #common idxs / #predicted idxs\n#Recall = #common idxs / #ground truth idxs\nrec = 0\nprec = 0\nfrom tqdm import tqdm\nfor i in tqdm(range(len(X_test[1:1000]))):\n\n    x=X_test[i]\n    y=y_test[i]\n    c=c_test[i]\n    pred = decode_accuracy2(x.reshape(1, max_q_len),c.reshape(1, max_c_len))\n    lcs_score = lcs(y, pred, len(y), len(pred))\n    if(len(pred) != 0):\n        prec += (lcs_score/len(pred))\n    else:\n        prec += (lcs_score/1)\n    rec += (lcs_score/len(y))\nprint('precision : ', (prec/len(X_test)))\nprint('recall : ', (rec/len(X_test)))\nprec = prec/len(X_test))\nrec = rec/len(X_test))\nf_meaure =  (2*prec*rec)/(prec+rec)\nprint('f_meaure :',f_meaure)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:13:32.289603Z","iopub.execute_input":"2022-04-02T08:13:32.290023Z","iopub.status.idle":"2022-04-02T08:17:07.011853Z","shell.execute_reply.started":"2022-04-02T08:13:32.28998Z","shell.execute_reply":"2022-04-02T08:17:07.011151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prec = prec/len(X_test)\nrec = rec/len(X_test)\nf_meaure =  (2*prec*rec)/(prec+rec)\nprint('f_meaure :',f_meaure)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:30:08.479771Z","iopub.execute_input":"2022-04-02T08:30:08.480024Z","iopub.status.idle":"2022-04-02T08:30:08.485848Z","shell.execute_reply.started":"2022-04-02T08:30:08.479996Z","shell.execute_reply":"2022-04-02T08:30:08.485025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculation of precision recall\n#X_train, X_test, y_train, y_test, c_train, c_test\n#Precision = #common idxs / #predicted idxs\n#Recall = #common idxs / #ground truth idxs\nrec = 0\nprec = 0\nfrom tqdm import tqdm\nfor i in tqdm(range(len(X_test[1:500]))):\n    x=X_test[i]\n    if(x[0]!=):\n        continue\n    y=y_test[i]\n    c=c_test[i]\n    pred = decode_accuracy2(x.reshape(1, max_q_len),c.reshape(1, max_c_len))\n    lcs_score = lcs(y, pred, len(y), len(pred))\n    if(len(pred) != 0):\n        prec += (lcs_score/len(pred))\n    else:\n        prec += (lcs_score/1)\n    rec += (lcs_score/len(y))\nprint('precision : ', (prec/len(X_test)))\nprint('recall : ', (rec/len(X_test)))\nf_meaure =  (2*prec*rec)/(prec+rec)\nprint('f_meaure :',f_meaure)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T19:43:30.61707Z","iopub.execute_input":"2022-04-01T19:43:30.617725Z","iopub.status.idle":"2022-04-01T19:43:30.624165Z","shell.execute_reply.started":"2022-04-01T19:43:30.617671Z","shell.execute_reply":"2022-04-01T19:43:30.623266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk import word_tokenize\nimport numpy as np\ndef demo(context, question):\n    q = re.sub(r'[^\\w\\s]', '', question_d.lower())\n    c = re.sub(r'[^\\w\\s]', '', context_d.lower())\n    q_d = word_tokenize(q)\n    q_d = [q_d]\n    c_d = word_tokenize(c)\n    c_d = [c_d]\n    q_d_t = np.array(x_tokenizer.texts_to_sequences(q_d))\n    c_d_t = np.array(x_tokenizer.texts_to_sequences(c_d))\n    q_d_p = pad_sequences(q_d_t,  maxlen=max_q_len, padding='post')\n    c_d_p = pad_sequences(c_d_t,  maxlen=max_c_len, padding='post')\n    print(decode_sequence2(q_d_p.reshape(1, max_q_len),c_d_p.reshape(1, max_c_len)))\n    #print(q_d_p.shape)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:26:21.460258Z","iopub.execute_input":"2022-04-02T08:26:21.460743Z","iopub.status.idle":"2022-04-02T08:26:21.904732Z","shell.execute_reply.started":"2022-04-02T08:26:21.460705Z","shell.execute_reply":"2022-04-02T08:26:21.903965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_d = \"Another important library – the University Library, founded in 1816, is home to over two million items. The building was designed by architects Marek Budzyński and Zbigniew Badowski and opened on 15 December 1999. It is surrounded by green. The University Library garden, designed by Irena Bajerska, was opened on 12 June 2002. It is one of the largest and most beautiful roof gardens in Europe with an area of more than 10,000 m2 (107,639.10 sq ft), and plants covering 5,111 m2 (55,014.35 sq ft). As the university garden it is open to the public every day.\"","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:47:04.196545Z","iopub.execute_input":"2022-04-02T08:47:04.196966Z","iopub.status.idle":"2022-04-02T08:47:04.205634Z","shell.execute_reply.started":"2022-04-02T08:47:04.196924Z","shell.execute_reply":"2022-04-02T08:47:04.204213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question_d = \"Who designed the garden for the University Library?\"","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:47:05.74667Z","iopub.execute_input":"2022-04-02T08:47:05.747062Z","iopub.status.idle":"2022-04-02T08:47:05.750832Z","shell.execute_reply.started":"2022-04-02T08:47:05.747029Z","shell.execute_reply":"2022-04-02T08:47:05.750133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"demo(context_d, question_d)\n#train_q[0:2],q_d","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:47:07.572825Z","iopub.execute_input":"2022-04-02T08:47:07.573414Z","iopub.status.idle":"2022-04-02T08:47:07.803695Z","shell.execute_reply.started":"2022-04-02T08:47:07.573358Z","shell.execute_reply":"2022-04-02T08:47:07.802969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}